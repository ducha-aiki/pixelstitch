{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "description: Simple, matplotlib based tool for hand-labeling the two-image correspondences\n",
    "output-file: index.html\n",
    "title: pyxelstitch\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| include: false\n",
    "from pixelstitch.core import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pip install pixelstitch`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test our annotator on a sample project. It needs a list of triplets: (`path_to_img1`, `path_to_img2`, `path_to_corrs_to_save`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('sample_project/ministry/01.png', 'sample_project/ministry/02.png', 'sample_project/ministry/corrs.txt'), ('sample_project/petrzin/01.png', 'sample_project/petrzin/02.png', 'sample_project/petrzin/corrs.txt')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/python39/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "rootdir = 'sample_project'\n",
    "pairs = os.listdir(rootdir)\n",
    "img_pairs_list = []\n",
    "for p in pairs:\n",
    "    if p == '.DS_Store':\n",
    "        continue\n",
    "    cur_dir = os.path.join(rootdir, p)\n",
    "    img_pairs_list.append((os.path.join(cur_dir, '01.png'),\n",
    "                           os.path.join(cur_dir, '02.png'),\n",
    "                           os.path.join(cur_dir, 'corrs.txt')))\n",
    "\n",
    "print (img_pairs_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to initialize `CorrespondenceAnnotator`. Don't forget to declare magic command ```%matplotlib widget```.\n",
    "**WITHOUT MAGIC IT WOULD NOT WORK**\n",
    "\n",
    "You also should explicitly specify, if you want to save (and possibly over-write previous better annotation) current correspondences automatically when clicking on **prev** and **next** buttons for going to the next pair. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/python39/lib/python3.9/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib widget\n",
    "from pixelstitch.core import *\n",
    "CA = CorrespondenceAnnotator(img_pairs_list, save_on_next=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can run the annotation. \n",
    "\n",
    "**Left-click** on the image to add a point \n",
    "\n",
    "**right-click** -- to remove the point from both images. \n",
    "\n",
    "### Matplotlib shortcuts:\n",
    "\n",
    "- **o** for zoom \n",
    "- **p** for pan (move)\n",
    "\n",
    "It is also recommended to set full page width for the jupyter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))\n",
    "CA.start(figsize=(12,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](index_files/att_00008.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Controls\n",
    "\n",
    "## Selectors\n",
    "\n",
    "- `Model`. One can select between \"`F`\" -- fundamental matrix and \"`H`\" -- homography. The selection influences the reprojection error type, and the visualization of the models and reprojection errors, shown when clicked on `NextCorrsValPoint`,  `NextCorrsValAll` and  `ShowModel` buttons.\n",
    "\n",
    "## Buttons\n",
    "\n",
    "- `NextCorrsValPoint`. Shows the correspondence in the bottom axis. The image title shows correspondence index and the reprojection error. If `Model` is `F`, it will show induced epipolar line, if `H` -- the position of the reprojected point from other image. The model is estimated with all other correspondences except current one. \n",
    "\n",
    "- `NextCorrsValAll`. Shows the correspondences in the bottom axis. Similar to `NextCorrsValPoint` button, but shows all points. The model is estimated with all  correspondences except current one, which index is shown in the title. \n",
    "![image.png](index_files/att_00005.png)\n",
    "\n",
    "\n",
    "- `ShowModel`. Has different behavoir depending on the `Model` selected. For `F` -- shows correspondences with their induced epipolar lines. Unlike `NextCorrsValPoint` and `NextCorrsValPoint` all correspondences are used for model estimation. \n",
    "![image.png](index_files/att_00003.png)\n",
    "\n",
    "- For `H`, the button shows overlay of image 1 reprojected into image2 with image2. The reprojected area is defined by the convex hull of the labelled correspondences. Next click flips the order, i.e. shows the image 2 reprojected into image 1.\n",
    "![image.png](index_files/att_00002.png)\n",
    "\n",
    "- `Save points` -- saves (overwrites) the correspondences into the text file.\n",
    "\n",
    "- `Prev` -- Loads and shows previous image pair to label. If the `CorrespondenceAnnotator` was initialized with `save_on_next=True`, the current pair correspondences are saved before the switch. Change is not cyclical, so the button does nothing on 1st image pair\n",
    "\n",
    "- `Next` -- Loads and shows next image pair to label. If the `CorrespondenceAnnotator` was initialized with `save_on_next=True`, the current pair correspondences are saved before the switch.Change is not cyclical, so the button does nothing on last image pair.\n",
    "\n",
    "- `CLAHE` -- Images are shown with enhanced contrast with [CLAHE](http://amroamroamro.github.io/mexopencv/opencv/clahe_demo_gui.html) algorithm.\n",
    "![image.png](index_files/att_00004.png)\n",
    "\n",
    "\n",
    "- `Pick 4 points for homography` -- Special mode. User picks 4 points in one image, which define new fronto-parallel view. This mode helps for labeling obscure views, see example below. The order of the points: top-left -> top-right -> bottom right -> bottom left. After the 4 point picked, the mode is switched off, so user needs to click the button again if she wants to rectify another image.\n",
    "\n",
    "- `ResetView` -- Resets any recifications or zoom done to images.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rectification picking mode example\n",
    "\n",
    "3 points are selected\n",
    "![image.png](index_files/att_00006.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All points are selected and image1 is rectified to the rectangle, defined by the selected points\n",
    "![image.png](index_files/att_00007.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
